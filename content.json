{"posts":[{"title":"OpenWrt多拨使用教程","text":"多拨类多拨相关的插件主要是 多线多拨 和 负载均衡 插件。 Syncdial 多线多拨使用macvlan驱动创建多个虚拟WAN口，支持并发多拨 1opkg install luci-app-syncdial MWAN3负载均衡支持多根网线或者多个PPPOE账号的同时拨号使用和负载均衡。并且还可以通过Ping方式来检测中断线路并自动屏蔽中断线路 1opkg install luci-i18n-mwan3-zh-cn 其他如发现无法安装或更新，请执行以下操作 更新OPKG软件列表1opkg update","link":"/2023/02/28/OpenWrt%E5%A4%9A%E6%8B%A8%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/"},{"title":"Obsidian 免费的实时同步服务","text":"使用 fly.io 免费计划部署或自托管数据库，进行 LiveSync 插件的一系列配置后实现各设备间 Obsidian 实时增量修改同步，可以和官方同步服务相媲美。 使用 fly.io这次使用的是 fly.io 的免费计划，fly.io 是一个 SAAS（是（Platform as a Service）的缩写，是指平台即服务）平台，可以搭建如静态博客、Nextjs、Nuxtjs、Deno、Go、Python 等底层的各种各样的服务。但首先需要自己注册一个账号，这里可以直接使用 Github 登录。 注意：fly.io 的使用需要绑卡，如果没有绑卡会在创建应用章节出现 Error 提示。绑卡过程请在 fly.io 面板中 Billing 进行。正常使用国内的双币卡就可以，注意请如实填写信息。没有卡的朋友可以去各银行办一张（超好过的😗）或试试虚拟卡？（虚拟卡只是博主想到的一种方案，没有试过） 安装 flyctlWindows 用户在本地打开 PowerShell 或 Windows 终端💻，输入： 1iwr https://fly.io/install.ps1 -useb | iex 注意：CMD 中不支持上面的命令，如果电脑中只有 CMD，或许你需要安装 PowerShell（选择 latest 版本）或 Windows 终端。 本地登录1flyctl auth signup 会自动打开浏览器进行验证账户操作。 创建应用在本地任意位置创建一个 fly.io 的工作目录（其实就是创建个能找到的文件夹，你不会放桌面上了吧😂？）。 1234mkdir fly.iocd fly.iomkdir couchdbcd couchdb 进入 couchdb 目录后输入命令： 1flyctl launch --image couchdb 这一步将会启动一个向导，按自己的需求进行选择。Select region 的意思是选择一个位置，尽量选择靠近自己的位置。 配置卷大小 我输入的配置卷大小命令为： 1flyctl volumes create --region nrt couchdata --size 1 nrt 的意思是东京地区，你需要改变为和上面选择的位置区域一样的位置代码。这一行命令的意思是：在东京地区创建一个 1G 大小的卷。 调整配置信息打开应用根目录的 fly.toml 文件，添加或修改如下信息： 根目录为在创建应用章节中创建的新文件夹 couchdb 博主是全部配置完毕后写这篇文章的😎，所有可能有遗漏或一些错误？为了保证严谨性，把自己的配置全部贴一份做对照吧： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# fly.toml file generated for couch-db on 2022-09-30T16:06:18+08:00app = &quot;couch-db&quot;kill_signal = &quot;SIGINT&quot;kill_timeout = 5processes = [][build] image = &quot;couchdb:latest&quot;[env] COUCHDB_USER = &quot;yantao&quot;[mounts] source=&quot;couchdata&quot; destination=&quot;/opt/couchdb/data&quot;[experimental] allowed_public_ports = [] auto_rollback = true[[services]] http_checks = [] internal_port = 5984 processes = [&quot;app&quot;] protocol = &quot;tcp&quot; script_checks = [] [services.concurrency] hard_limit = 25 soft_limit = 20 type = &quot;connections&quot; [[services.ports]] force_https = true handlers = [&quot;http&quot;] port = 80 [[services.ports]] handlers = [&quot;tls&quot;, &quot;http&quot;] port = 443 [[services.ports]] handlers = [&quot;tls&quot;, &quot;http&quot;] port = 5984 [[services.tcp_checks]] grace_period = &quot;1s&quot; interval = &quot;15s&quot; restart_limit = 0 timeout = &quot;2s&quot; 请对比上面提供的配置文件修改自己的 fly.toml 文件。 设置密码在终端中输入命令： 1flyctl secrets set COUCHDB_PASSWORD=你的密码 注意：密码使用大小写字母与数字，不要使用特殊字符。实际测试后发现使用特殊字符时无法识别密码，会无法登录数据库。 如果想要修改密码，可以再次运行上面的命令。 部署 注意，如果提示 Services defined at indexes: 0 require a dedicated IP address. You currently have no dedicated IPs allocated. Please allocate at least one dedicated IP before deploying，那么需要运行 fly ips allocate-v4。 在终端中输入命令： 1flyctl deploy 稍作等待后提示部署成功🎉。使用下面命令可以打开网页登录： 1flyctl open 如果是 fly.io 部署，那么在网址后加 `/_utils/#/setup`，跳转后可以输入用户名与密码。 网页成功登录，好耶🎉 网页数据库配置这一大章节都在网页中进行。如果不知道自己的地址，可以打开 fly.io 面板，点击自己的应用，Hostname 处为自己应用的网址。 创建数据库 点击右上角的 Create Database，创建一个数据库，Database name 为数据库名字，Partitioned 请不要勾选，然后点 Create 创建。 配置其他信息打开 Setup 选项卡，填写相关信息。 第一行的 Specify your Admin credentials 为你在上面步骤中配置的用户信息。第二行的 Bind address the node will listen on 意思是监听的访问地址，设置为 0.0.0.0 为允许所有 ip 访问。第三行的 Port that the node will use 为你在 调整配置信息 这一步中的 fly.toml 文件中配置的端口，如果和我设置的一样，那这里应该是 5984😚。设置完成后会显示 Apache CouchDB is configured for production usage as a clustered node! Do you want to replicate data?，代表配置成功。 启用 CORS 然后打开 Configuration 选项卡中的 CORS 标签，启用 CORS。完成网页端操作！ 下方的 Origin Domains 需要设置为 All domains。 Obsidian 设置这一章节的操作都在 Obsidian 本体软件中进行。首先需要关闭 Obsidian 中的安全模式，在插件市场中搜索 Self-hosted LiveSync 下载并启用。在 Github 仓库中手动下载安装本插件可能会出现一些问题。 在移动端可能会打不开插件市场，是众所周知的网络原因，需要自己解决😑。 配置连接信息打开 Remote Database configuration 选项卡。输入自己的数据库网址、用户名、密码与数据库名。 数据库网址 URI 为 https://你的应用.fly.dev 的形式，如果找不到可以使用 flyctl open 或在 fly.io 面板中打开自己的应用查看 Hostname 项。 用户名与密码为在调整配置信息时填写的用户名与在设置密码中用命令设置的密码。 数据库名为在创建数据库时创建的数据库名。 ### 修复连接 点击 Test Database Connection，在右上角出现 Connect to 数据库名，则为连接成功。然后点击 Check database configuration，会出现一堆日志，逐个点击后面的 fix 按钮修复即可。 修复完成后重新点击 Check database configuration，没有出现 fix 按钮即为修复成功。 同步设置打开 Sync Settings 选项卡，其中有所有的同步方式设置。注意：实时同步 (LiveSync) 与定时同步 (Periodic Sync) 互斥，无法同时打开。 可能有朋友会纠结用哪个，在这里强烈推荐使用 LiveSync（实时同步）方式，毕竟用此插件就是为了这个。因为 Periodic Sync（定时同步）中包含有 Sync on Save (保存时同步)、Sync on File Open (文件打开时同步)、Sync on Start (打开软件时同步) 各种选项，合计一下完全就是变相的实时同步嘛！第二点是当我使用 hugo server 开启本地博客变更监听后发现，Obsidian 会自动在输入文字后保存一次，造成频繁的 Sync on Save (保存时同步) 操作。所以，还是使用 LiveSync（实时同步）吧👍。 其他设置在 Sync Settings 选项卡中还包含有 Use Trash for deleted files（删除文件到回收站）配置强烈建议打开，防止文件意外丢失。 在 Miscellaneous 选项卡（一个小扳手图标）中，有选项 Show staus inside editor（在编辑器右上角显示当前同步状态），推荐打开。 同步状态将显示在状态栏，状态都有： ⏹️ 准备就绪 💤 LiveSync 已启用，正在等待更改 ⚡️ 同步中 ⚠️ 出现错误 信息解释： ↑ 上传的 chunk 和元数据数量 ↓ 下载的 chunk 和元数据数量 ⏳ 等待的过程的数量 🧩 正在等待 chunk 的文件数量 如果你删除或修改了文件名称，请等待 ⏳ 图标消失。 安装于其他设备在插件 Setup wizard 选项卡中，点击 Copy Setup URI，弹出的对话框输入你的数据库密码，即可复制当前的配置信息。在其他如 Android、iOS 设备上安装此插件并点击 Open Setup URI 输入复制的链接即可。 在这里选第一个，意思为将此设备设置为辅助或后续设备。稍等一会儿后即可同步完成。而且同步非常快，只需要几秒钟就好。 这里放一张官网的同步动态图可以感受一下。 推荐方案值得注意的是，不应该在 Obsidian 中存放太多媒体文件，如：Markdown 文件直接引用本地图片或音频。不然会显著拖慢任何 WebDAV 或 LiveSync 的同步速度。做一个对比，我的 Obsidian 中大概有 80 篇左右笔记与博文，本地源文件只有 600KB，数据库占用只有 2MB 左右。如果使用本地引用图片，那么一张图片就能抵得上我全部笔记的大小，同步时间将成倍的增长🙄。所以，这些媒体文件更应该放入图床或对象存储中，使用 ![]() 的形式引用。 后记fly.io 部署的服务体验太好了💖。Obsidian 各端同步起来非常快，虽然看面板只是一个 256MB 的小机器，但是这个任务完全可以胜任。fly.io 每个账户的免费资源包括：总共 3GB 的卷、最多 3 个共享 CPU-1x 256MB 虚拟机、每月 160GB 出站数据传输。看起来还能做一些新玩法的样子。在对比使用 Remotely save 同步后发现，同步速度除了快就是快，刚在电脑上写完一句话，想起有事情准备走，拿起手机打开 Obsidian，完全可以接着继续编辑，无缝同步的体验真是太棒了！我宣布这是 Obsidian 非官方同步服务的最佳方式。","link":"/2023/03/06/Obsidian%20%E5%85%8D%E8%B4%B9%E7%9A%84%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1/"},{"title":"Python ChatGPT Telegram Bot","text":"注册这里如何注册我就不说明了，大家自行去注册，主要是现在GPT的基本上已经备用很多了，导致了接码的价格也上涨了，而且使用token的话，其实还是很快可以用完免费的18美金；接码：https://sms-activate.org/ 准备材料主要提供下Python的实现代码，首先需要准备一下的东西： Telegram Bot 的 Key ：找机器人爸爸获取 ChatGPT 的 API Key ： https://platform.openai.com/account/api-keys 脚本：main.py >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145# 1. Start by importing the necessary libraries and setting up the API clients import requests import json import os import threading # OpenAI secret Key API_KEY = 'xxxxxxxxx' # Models: text-davinci-003,text-curie-001,text-babbage-001,text-ada-001 MODEL = 'text-davinci-003' # Telegram secret access bot token BOT_TOKEN = 'xxxxxxxxxxxxx' # Defining the bot's personality using adjectives BOT_PERSONALITY = '' # 2a. Function that gets the response from OpenAI's chatbot def openAI(prompt): # Make the request to the OpenAI API response = requests.post( 'https://api.openai.com/v1/completions', headers={'Authorization': f'Bearer {API_KEY}'}, json={'model': MODEL, 'prompt': prompt, 'temperature': 0.4, 'max_tokens': 4000} ) result = response.json() print(result) final_result = ''.join(choice['text'] for choice in result['choices']) return final_result # 2b. Function that gets an Image from OpenAI def openAImage(prompt): # Make the request to the OpenAI API resp = requests.post( 'https://api.openai.com/v1/images/generations', headers={'Authorization': f'Bearer {API_KEY}'}, json={'prompt': prompt, 'n': 1, 'size': '1024x1024'} ) response_text = json.loads(resp.text) return response_text['data'][0]['url'] # 3a. Function that sends a message to a specific telegram group def telegram_bot_sendtext(bot_message, chat_id, msg_id): data = { 'chat_id': chat_id, 'text': bot_message, 'reply_to_message_id': msg_id } response = requests.post( 'https://api.telegram.org/bot' + BOT_TOKEN + '/sendMessage', json=data ) return response.json() # 3b. Function that sends an image to a specific telegram group def telegram_bot_sendimage(image_url, group_id, msg_id): data = { 'chat_id': group_id, 'photo': image_url, 'reply_to_message_id': msg_id } url = 'https://api.telegram.org/bot' + BOT_TOKEN + '/sendPhoto' response = requests.post(url, data=data) return response.json() # 4. Function that retrieves the latest requests from users in a Telegram group, # generates a response using OpenAI, and sends the response back to the group. def Chatbot(): # Retrieve last ID message from text file for ChatGPT update cwd = os.getcwd() filename = cwd + '/chatgpt.txt' if not os.path.exists(filename): with open(filename, &quot;w&quot;) as f: f.write(&quot;1&quot;) else: print(&quot;File Exists&quot;) with open(filename) as f: last_update = f.read() # Check for new messages in Telegram group url = f'https://api.telegram.org/bot{BOT_TOKEN}/getUpdates?offset={last_update}' response = requests.get(url) data = json.loads(response.content) for result in data['result']: try: # Checking for new message if float(result['update_id']) &gt; float(last_update): # Checking for new messages that did not come from chatGPT if not result['message']['from']['is_bot']: last_update = str(int(result['update_id'])) # Retrieving message ID of the sender of the request msg_id = str(int(result['message']['message_id'])) # Retrieving the chat ID chat_id = str(result['message']['chat']['id']) # Checking if user wants an image if '/img' in result['message']['text']: prompt = result['message']['text'].replace(&quot;/img&quot;, &quot;&quot;) bot_response = openAImage(prompt) print(telegram_bot_sendimage(bot_response, chat_id, msg_id)) # Checking that user mentionned chatbot's username in message if '@chatGpt_dandelion_bot' in result['message']['text'] \\ or '/ask' in result['message']['text']: prompt = result['message']['text'].replace(&quot;@chatGpt_dandelion_bot&quot;, &quot;&quot;) # Calling OpenAI API using the bot's personality bot_response = openAI(f&quot;{BOT_PERSONALITY}{prompt}&quot;) # Sending back response to telegram group print(telegram_bot_sendtext(bot_response, chat_id, msg_id)) # Verifying that the user is responding to the ChatGPT bot if 'reply_to_message' in result['message']: if result['message']['reply_to_message']['from']['is_bot']: prompt = result['message']['text'] bot_response = openAI(f&quot;{BOT_PERSONALITY}{prompt}&quot;) print(telegram_bot_sendtext(bot_response, chat_id, msg_id)) except Exception as e: print(e) # Updating file with last update ID with open(filename, 'w') as f: f.write(last_update) return &quot;done&quot; # 5 Running a check every 5 seconds to check for new messages def main(): timertime = 5 Chatbot() # 5 sec timer threading.Timer(timertime, main).start() # Run the main function if __name__ == &quot;__main__&quot;: main()","link":"/2023/02/21/Python%20ChatGPT%20Telegram%20Bot/"},{"title":"通过 Haproxy 实现 Shadowshadows 负载均衡","text":"介绍缺点：所有的SS的加密方式和密码必须一致介绍：HAProxy是一个使用C语言编写的自由及开放原始码软件，其提供高可用性、负载均衡，以及基于TCP和HTTP的应用程序代理。 安装Haproxy1yum install haproxy 配置12345678910111213141516171819202122232425262728293031323334353637global chroot /var/lib/haproxy pidfile /var/run/haproxy.pid user haproxy group haproxydefaults mode tcp #服务器默认的工作模式 balance roundrobin #服务器默认使用的均衡模式 retries 3 #三次连接失败表示服务器不可用 maxconn 5000 #最大连接数 timeout connect 500ms #连接超时 timeout client 3s #客户端超时 timeout server 3s #服务器超时listen WebPanel mode http #这里使用HTTP模式 bind 10.1.1.58:9595 #WEB服务端口 stats refresh 5s #自动刷新时间 stats uri / #WEB管理地址 stats auth admin:xxxx #账号密码 stats hide-version #隐藏版本 stats admin if TRUE #验证通过则赋予管理权frontend shadowsocks-in bind *:50001 default_backend serversbackend servers mode tcp balance roundrobin # option external-check option tcp-check # external-check command &quot;/etc/haproxy/haproxy-shadowsocks-checker.py&quot; server ss1 43.156.100.84:2195 check inter 500 rise 2 fall 4 weight 100 #SS/SSR服务器地址与端口 server ss2 42.157.192.42:10108 check inter 500 rise 2 fall 4 weight 100 server：后面首先跟名字，名字随便起呗，自己能够区分就行。紧接着跟SS的公网IP+端口，端口也就是SS/SSR的端口。check：是检测的意思，这段配置很重要inter：单位毫秒，我配置的500，即500毫秒检测一次目标服务器。rise2：设定健康状态检查中，某离线的服务器从离线状态转换至正常状态需要成功检查的次数，这里我设置的2次。fall4：确认服务器从正常状态转换为不可用状态需要检查的次数，这里是4次。weight：权重，值越大代表这台机器工作的机会越多，这里我们可以把一台线路较好的机器的权重设置高一些。balance：负载均衡方式 roundrobin：基于权重进行轮叫，在服务器的处理时间保持均匀分布时，这是最平衡、最公平的算法。此算法是动态的，这表示其权重可以在运行时进行调整，不过，在设计上，每个后端服务器仅能最多接受4128个连接； static-rr：基于权重进行轮叫，与roundrobin类似，但是为静态方法，在运行时调整其服务器权重不会生效；不过，其在后端服务器连接数上没有限制； leastconn：新的连接请求被派发至具有最少连接数目的后端服务器；在有着较长时间会话的场景中推荐使用此算法，如LDAP、SQL等，其并不太适用于较短会话的应用层协议，如HTTP；此算法是动态的，可以在运行时调整其权重； source：将请求的源地址进行hash运算，并由后端服务器的权重总数相除后派发至某匹配的服务器；这可以使得同一个客户端IP的请求始终被派发至某特定的服务器；不过，当服务器权重总数发生变化时，如某服务器宕机或添加了新的服务器，许多客户端的请求可能会被派发至与此前请求不同的服务器；常用于 负载均衡无cookie功能的基于TCP的协议；其默认为静态，不过也可以使用hash-type修改此特性； 修改Shadowsocks配置123456789{ &quot;server&quot;:&quot;127.0.0.1&quot;, # 这里改成Haproxy的地址 &quot;server_port&quot;:50001, # 这里改成Haproxy监听的端口 &quot;local_port&quot;:1080, # 这里本地监听端口 &quot;password&quot;:&quot;qunheadmin&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-256-gcm&quot;, &quot;mode&quot;:&quot;tcp_and_udp&quot;}","link":"/2022/12/13/haproxy-load/"},{"title":"linux通过SNMP检测TCP&amp;UDP连接数","text":"先上图&amp;介绍记录一次全球化网络监控的看板建设；之前都是通过zabbix来进行建设看板，但是用了一段时间后总是缺点感觉；后面通过大佬的介绍，试用了Grafana，这不试用还好，一试用，效果的展现让我无法自拔，这就是我想要的监控看板啊！能根据数值的不同进行颜色的区分，在大屏上一眼就可以看出当前哪一块网络出现了问题！ 美中不足的是，上面的两列不能设置报警，报警貌似必须是图表形式的才可以；不过可以建立一个通用的报警看板，问题不大～ 其他的一些监控项都是最简单基础的，我这边就不过多的赘述，大家可以自行上网搜索，或者之前引用之前zabbix的数据，主要讲解下TCP连接数和UDP连接数的获取 别的不说，这图还是很好看的； 现在讲讲获取TCP/UDP连接数的准备 SNMP (yum install snmpd) 自定义OID 创建获取连接数脚本1234#!/bin/bashecho $2echo integerecho $(netstat -an|awk '/^tcp/ {++s[$NF]} END {for(a in s ) print a,s[a]}' | grep ESTABLISHED | awk '{print $2}') 这个是获取TCP连接数的脚本，如果要获取UDP的，请把tcp改成udp设置脚本权限 1chmod 766 zabbix.tcp.sh 修改SNMP配置文件文件路径：/etc/snmp/snmpd.conf 1pass .1.3.6.1.4.1.2021.21 /etc/snmp/shell/zabbix.tcp.sh 在最底下加入这条命令，后面的shell脚本就是上传创建的脚本路径 重启SNMP服务1service snmpd restart 后记通过这种方式，我们就可以做更多的扩展，比如 获取连接人数 当前访问情况 …","link":"/2023/03/11/linux%E9%80%9A%E8%BF%87SNMP%E6%A3%80%E6%B5%8BTCP&UDP%E8%BF%9E%E6%8E%A5%E6%95%B0/"},{"title":"curl 检测代理的可用性以及延迟","text":"背景在办公网的代理翻墙的过程中，经常没办法第一时间知道代理失效了，因为我们自身不是高用的用户，每次挂了都需要员工来反馈，体感非常的不好，因此想着可以通过zabbix如果把当前的延迟、可用性检测起来 通过Curl 检测Google的延迟这里为啥是curl而不是ping，因为默认ping事不支持代理的，然而curl也可以做到真正的是否可用 1curl -o /dev/null -x socks5h://127.0.0.1:12126 -s --connect-timeout 5 -w %{time_starttransfer}&quot;\\n&quot; $1 socks5h的地址需要改成你的代理地址 12345678910# 获取当前代理的可用性```bashurl=$1result=($(curl -x socks5h://localhost:12126 -I -s --connect-timeout 5 ${url} | head -1 | tr &quot;\\r&quot; &quot;\\n&quot;))if [ &quot;${result[1]}&quot; == $2 -a &quot;${result[2]}&quot; == 'OK' ]then echo 1else echo 0fi zabbix操作脚本12345# 延迟UserParameter=googleTime[*],/etc/zabbix/script/googleTime.sh $1# 可用UserParameter=googleCheck[*],/etc/zabbix/script/googleCheck.sh $1 $2","link":"/2023/02/20/curl%20%E6%A3%80%E6%B5%8B%E4%BB%A3%E7%90%86%E7%9A%84%E5%8F%AF%E7%94%A8%E6%80%A7%E4%BB%A5%E5%8F%8A%E5%BB%B6%E8%BF%9F/"},{"title":"ss-tproxy 透明代理的设置方法","text":"一、介绍1、什么是透明代理在正向代理中，一个软件如果想走 client 的代理服务，我们必须显式配置该软件，对该软件来说，有没有走代理是很明确的，大家都“心知肚明”。而透明代理则与正向代理相反，当我们设置好合适的防火墙规则（仅以 Linux 的 iptables 为例），我们将不再需要显式配置这些软件来让其经过代理或者不经过代理（直连），因为这些软件发出的流量会自动被 iptables 规则所处理，那些我们认为需要代理的流量，会被通过合适的方法发送到 client 进程，而那些我们不需要代理的流量，则直接放行（直连）。这个过程对于我们使用的软件来说是完全透明的，软件自身对其一无所知。这就叫做 透明代理。注意，所谓透明是对我们使用的软件透明，而非对 client、server 或目标网站透明，理解这一点非常重要。 2、透明代理的工作原理在正向代理中，期望使用代理的软件会通过 http、socks5 协议与 client 进程进行交互，以此完成代理操作。而在透明代理中，我们的软件发出的流量是完全正常的流量，并没有像正向代理那样，使用 http、socks5 等专用协议，这些流量经过 iptables 规则的处理后，会被通过“合适的方法”发送给 client 进程（当然是指那些我们认为需要走代理的流量）。注意，此时 client 进程接收到不再是 http、socks5 协议数据，而是经过 iptables 处理的“透明代理数据”，“透明代理数据”从本质上来说与正常数据没有区别，只是多了一些“元数据”在里面，使得 client 进程可以通过 netfilter 或操作系统提供的 API 接口来获取这些元数据（元数据其实就是原始目的地址和原始目的端口）。那么这个“合适的方法”是什么？目前来说有两种： REDIRECT：只支持 TCP 协议的透明代理。 TPROXY：支持 TCP 和 UDP 协议的透明代理。 因此，对于 TCP 透明代理，有两种实现方式，一种是 REDIRECT，一种是 TPROXY；而对于 UDP 透明代理，只能通过 TPROXY 方式来实现。为方便叙述，本文以 纯 TPROXY 模式 指代 TCP 和 UDP 都使用 TPROXY 来实现，以 REDIRECT + TPROXY 模式 指代 TCP 使用 REDIRECT 实现，而 UDP 使用 TPROXY 来实现，有时候简称 REDIRECT 模式，它们都是一个意思。 二、Openvpn流量转发采用：https://github.com/zfl9/ss-tproxy原理：openvpn → iptables → ss-redir 三、部署方式1、依赖检查在部署之前，需要检查下当前自己的服务器依赖是否完整：依赖安装地址：https://github.com/zfl9/ss-tproxy/wiki/Linux-%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86#%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96 2、脚本安装123git clone https:``//github.com/zfl9/ss-tproxycd ss-tproxychmod +x ss-tproxy install 可用的情况下（推荐）1234install ss-tproxy /usr/local/bininstall -d /etc/ss-tproxyinstall -m` `644` `ss-tproxy.conf gfwlist* chnroute* ignlist* /etc/ss-tproxyinstall -m` `644` `ss-tproxy.service /etc/systemd/system # 可选，安装 service 文件 install 不可用1234cp -af ss-tproxy /usr/local/binmkdir -p /etc/ss-tproxycp -af ss-tproxy.conf gfwlist* chnroute* ignlist* /etc/ss-tproxycp -af ss-tproxy.service /etc/systemd/system # 可选，安装 service 文件 配置文件： /etc/ss-tproxy/ss-tproxy.conf >folded123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# mode#mode='global' # global 模式 (不分流)mode='gfwlist' # gfwlist 模式 (黑名单)#mode='chnroute' # chnroute 模式 (白名单) # ipv4/6ipv4='true' # true:启用ipv4透明代理; false:关闭ipv4透明代理ipv6='false' # true:启用ipv6透明代理; false:关闭ipv6透明代理 # tproxytproxy='false' # true:TPROXY+TPROXY; false:REDIRECT+TPROXY # tcponlytcponly='false' # true:仅代理TCP流量; false:代理TCP和UDP流量 # selfonlyselfonly='false' # true:仅代理本机流量; false:代理本机及&quot;内网&quot;流量 # proxy# user/group(#1,推荐) vs svraddr+port(#2), user/group选其中一个填写(不建议都填)proxy_procuser='proxy' # 本机代理进程的 user/uid，用来放行本机代理进程传出的流量proxy_procgroup='' # 本机代理进程的 group/gid，用来放行本机代理进程传出的流量proxy_svraddr4=() # 服务器的 IPv4 地址或域名，允许填写多个服务器地址，空格隔开proxy_svraddr6=() # 服务器的 IPv6 地址或域名，允许填写多个服务器地址，空格隔开proxy_svrport='' # 服务器的监听端口，可填多个端口，格式同 ipts_proxy_dst_portproxy_tcpport='12121' # ss/ssr/v2ray 等本机进程的 TCP 监听端口，该端口支持透明代理proxy_udpport='12121' # ss/ssr/v2ray 等本机进程的 UDP 监听端口，该端口支持透明代理proxy_startcmd='(ss-redir -c /etc/shadowsocks-libev/config.json -u &lt;/dev/null &amp;&gt;&gt;/var/log/ss-redir.log &amp;)' # 用于启动本机代理进程的 shell 命令，该命令应该能立即执行完毕proxy_stopcmd='kill -9 $(pidof ss-redir)' # 用于关闭本机代理进程的 shell 命令，该命令应该能立即执行完毕 # dnsdns_direct='223.5.5.5' # 本地 IPv4 DNS，不能指定端口，也可以填组织、公司内部 DNSdns_direct6='240C::6666' # 本地 IPv6 DNS，不能指定端口，也可以填组织、公司内部 DNSdns_remote='8.8.8.8#53' # 远程 IPv4 DNS，必须指定端口，提示：访问远程 DNS 会走代理dns_remote6='2001:4860:4860::8888#53' # 远程 IPv6 DNS，必须指定端口，提示：访问远程 DNS 会走代理 # dnsmasqdnsmasq_bind_port='53' # dnsmasq 服务器监听端口，见 READMEdnsmasq_cache_size='4096' # DNS 缓存大小，大小为 0 表示禁用缓存dnsmasq_cache_time='3600' # DNS 缓存时间，单位是秒，最大 3600 秒dnsmasq_query_maxcnt='1024' # 设置并发 DNS 查询的最大数量，默认为 150dnsmasq_log_enable='false' # 记录详细日志，除非进行调试，否则不建议启用dnsmasq_log_file='/var/log/dnsmasq.log' # 日志文件，如果不想保存日志可以改为 /dev/nulldnsmasq_conf_dir=() # `--conf-dir` 选项的参数，可以填多个，空格隔开dnsmasq_conf_file=() # `--conf-file` 选项的参数，可以填多个，空格隔开dnsmasq_conf_string=() # 自定义配置，一个数组元素就是一行配置，空格隔开 # chinadnschinadns_bind_port='65353' # chinadns-ng 服务器监听端口，通常不用改动chinadns_timeout='5' # 等待上游 DNS 返回响应的超时时间，单位为秒chinadns_repeat='1' # 向可信 DNS 发送几次 DNS 查询请求，默认为 1chinadns_fairmode='true' # 使用公平模式，具体看 chinadns-ng 的 READMEchinadns_gfwlist_mode='true' # gfwlist 模式，加载 gfwlist.txt/gfwlist.extchinadns_noip_as_chnip='false' # 启用 chinadns-ng 的 `--noip-as-chnip` 选项chinadns_verbose='false' # 记录详细日志，除非进行调试，否则不建议启用chinadns_logfile='/var/log/chinadns.log' # 日志文件，如果不想保存日志可以改为 /dev/nullchinadns_privaddr4=() # IPv4 私有地址段，多个用空格隔开，具体见 READMEchinadns_privaddr6=() # IPv6 私有地址段，多个用空格隔开，具体见 README # dns2tcpdns2tcp_bind_port='65454' # dns2tcp 转发服务器监听端口，如有冲突请修改dns2tcp_tcp_syncnt='' # dns2tcp 的 `-s` 选项，留空表示不设置此选项dns2tcp_tcp_quickack='false' # dns2tcp 的 `-a` 选项，选项取值为true/falsedns2tcp_tcp_fastopen='false' # dns2tcp 的 `-f` 选项，选项取值为true/falsedns2tcp_verbose='false' # 记录详细日志，除非进行调试，否则不建议启用dns2tcp_logfile='/var/log/dns2tcp.log' # 日志文件，如果不想保存日志可以改为 /dev/null # iptsipts_if_lo='lo' # 环回接口的名称，在标准发行版中，通常为 lo，如果不是请修改ipts_rt_tab='233' # iproute2 路由表名或表 ID，除非产生冲突，否则不建议改动该选项ipts_rt_mark='0x2333' # iproute2 策略路由的防火墙标记，除非产生冲突，否则不建议改动该选项ipts_set_snat='true' # 设置 iptables 的 MASQUERADE 规则，布尔值，`true/false`，详见 READMEipts_set_snat6='false' # 设置 ip6tables 的 MASQUERADE 规则，布尔值，`true/false`，详见 READMEipts_reddns_onstop='true' # ss-tproxy stop 后，是否将其它主机发至本机的 DNS 重定向至直连 DNS，详见 READMEipts_proxy_dst_port='1:65535' # 黑名单 IP 的哪些端口走代理，多个用逗号隔开，冒号为端口范围(含边界)，详见 README # optsopts_ss_netstat='auto' # auto/ss/netstat，用哪个端口检测工具，见 READMEopts_ping_cmd_to_use='auto' # auto/standalone/parameter，ping 相关，见 READMEopts_hostname_resolver='auto' # auto/dig/getent/ping，用哪个解析工具，见 READMEopts_overwrite_resolv='false' # true/false/留空，如何操作 resolv.conf，见 READMEopts_ip_for_check_net='223.5.5.5' # 检测外网是否可访问的 IP，ping，留空表示跳过此检查 # filefile_gfwlist_txt='/etc/ss-tproxy/gfwlist.txt' # gfwlist/chnlist 模式预置文件file_gfwlist_ext='/etc/ss-tproxy/gfwlist.ext' # gfwlist/chnlist 模式扩展文件file_ignlist_ext='/etc/ss-tproxy/ignlist.ext' # global/chnroute 模式扩展文件file_chnroute_set='/etc/ss-tproxy/chnroute.set' # chnroute 地址段文件 (iptables)file_chnroute6_set='/etc/ss-tproxy/chnroute6.set' # chnroute6 地址段文件 (ip6tables)file_dnsserver_pid='/etc/ss-tproxy/.dnsserver.pid' # dns 服务器进程的 pid 文件 (shell) # 主要放通下内网的访问，然后把MASQUERADE提前出来，要不然tcp的连接会回不来post_start(){iptables -t nat -I PREROUTING -s 10.207.0.0/16 -d 10.0.0.0/8 -j ACCEPTiptables -t nat -I SSTP_POSTROUTING -s 10.207.0.0/16 -j MASQUERADE} post_stop(){iptables -t nat -D PREROUTING -s 10.207.0.0/16 -d 10.0.0.0/8 -j ACCEPTiptables -t nat -D SSTP_POSTROUTING -s 10.207.0.0/16 -j MASQUERADE} 以下配置需要特别注意，如果不知道如何配置的，那么就按照我这么默认配置即可具体配置介绍：https://github.com/zfl9/ss-tproxy#%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E 3、设置ss-libev代理12345678910#新版本(v4.``6.1``及以上)#第一次运行时，请执行下面这两个操作#``1``.创建proxy用户和组: useradd -Mr -d/tmp -s/bin/bash proxy#``2``.授予透明代理相关权限: setcap cap_net_bind_service,cap_net_admin+ep /path/to/ss-redir#&gt;&gt; 若setcap不可用，可使用suid权限位，此时需配置：proxy_procuser=``''``、proxy_procgroup=``'proxy'#&gt;&gt; 将所有者(组)改为root，并授予suid权限：chown root:root /path/to/ss-redir &amp;&amp; chmod` `4755` `/path/to/ss-redirproxy_procuser=``'proxy'#proxy_startcmd=``'su proxy -c&quot;(ss-redir -c /etc/ss.json -u -v &lt;/dev/null &amp;&gt;&gt;/tmp/ss-redir.log &amp;)&quot;'` `# -v 表示记录详细日志proxy_startcmd=``'su proxy -c&quot;(ss-redir -c /etc/ss.json -u &lt;/dev/null &amp;&gt;&gt;/tmp/ss-redir.log &amp;)&quot;'` `# 这里就不记录详细日志了proxy_stopcmd=``'kill -9 $(pidof ss-redir)' 黑名单、白名单说明 对于 global 模式，白名单文件为 ignlist.ext，没有黑名单文件，因为默认都走代理。 对于 gfwlist 模式，黑名单文件为 gfwlist.txt/ext，没有白名单文件，因为其它都走直连。 对于 chnroute 模式，白名单文件为 ignlist.ext，没有黑名单文件，但允许开启此功能，见下。如果想让 chnroute 模式支持黑名单扩展，请打开 chinadns-ng 的 gfwlist 模式（chinadns_gfwlist_mode）；开启 gfwlist 模式后，chinadns-ng 会读取 gfwlist.txt/ext 黑名单文件中的域名模式；当 chinadns-ng 收到域名解析请求时，会先检查给定域名是否在黑名单中，如果是则只向可信 DNS 发出解析请求（也就是 dns_remote/dns_remote6），因此解析出来的会是国外 IP（不一定，具体要看给定域名的A/AAAA记录以及其dns解析设定），然后当客户端访问该 IP 时就会走代理出去了（如果解析的地址是国外地址）。 chinadns_gfwlist_mode的本意其实并不是为了支持’黑名单’，而是为了提高 chinadns-ng 的准确性，降低 dns 污染的可能性 启动后，ss-tproxy会自动帮你做透明代理，会设置好iptables的配置，不需要在手工配置同时ss-tproxy还提供勾子的形式，来帮助解决分流或者内网访问的一个方案，具体参考： https://github.com/zfl9/ss-tproxy#%E9%92%A9%E5%AD%90%E5%87%BD%E6%95%B0 https://github.com/zfl9/ss-tproxy#%E9%92%A9%E5%AD%90%E5%87%BD%E6%95%B0%E5%B0%8F%E6%8A%80%E5%B7%A7","link":"/2023/02/16/ssTproxyTransparentAgent/"},{"title":"记录一次办公网全球化的改造计划","text":"背景办公网每次去海外找资料都需要重新连接VPN，或者自己连接自己买的小飞机之类的才可以。但是这种在互联网公司内的话，非常的不友好；为公司工作还要自己花钱买小飞机～ 之前尝试过下面这种方式：新增一台海外的机器（新加坡、香港）搭建SS/v2ray/trojan之类的协议，然后办公网新增一个软路由去连接，通过ACL把部分IP的用户跳转过去；但是这种方式自己家里用用还行，如果想要在企业的办公网来使用的话，人一多就不行，因为所有人都从这个IP出去了，而且每次都需要命令行去操作ACL增加用户，非常的麻烦； 名词介绍 名词 介绍 Panabit Panabit是国内X86平台单板处理能力最高（双向40G）、在运营商和高校等行业案例过千（X运营商千兆以上规格共计400余台已普遍连续稳定运行至第7年），实时对超过3TB的网络带宽进行DPI识别与优化服务、并针对中小企业提供免费版本（软件形态），是以DPI为核心优势并发展起来的专业、上线效果好、性价比高的新一代应用网关。进入2014年，实际支持国内应用协议超过800种，并已集成路由、负载均衡、认证、一拖N检测、移动终端识别、DNS管控、HTTP管控、日志审计等实用功能于一体。 Panabit 的 Iwan为了解决前面的这种方式，决定测试使用 Panabit 的 Iwan 的方式，也就是所谓的 Panabit 的 SD-WAN； 重连速度很快： 比L2TP的要快一个数量级，L2TP要重连，需要有几十次交互，而我们只需要一次即可 客户端不受底层承载线路IP变化影响： 当底层承载线路（比如PPPOE拨号线路）的IP地址发生变化时，不会影响iWAN隧道，iWAN隧道不会中断，保证通信正常进行； 因为很多用户是通过PPPOE拨号线路出去的，PPPOE拨号线路重拨时一般会改变IP地址，如果用L2TP的话，那么这个L2TP会话就要重建； 而用iWAN的话，现有的会话可以照常使用，不需要做任何改变； 传输效率高： iWAN的包头很小，只有8个字节，而且在后续版本里，我们会压缩IP报文头，这样可以继续减少额外报文头的大小，所以能大幅度提升传输效率； 如果用国际线路的话，节省下来的流量费用都是很可观的； 抗干扰： 不像L2TP，中间人可以直接发包TERMINATE，iWAN控制命令有完整性检查，可以避免中间人攻击。 部署1、搭建panabit记得服务器申请2H的，1H需要需改核心，非常麻烦下载Linux系统文件：文末上传文件到root根目录下 1234tar -xzf PanabitFREE_SUIr2p3_20220413_Linux3.tar.gzcd PanabitFREE_SUIr2p3_20220413_Linux3# 输入以下命令进行安装./ipeinstall 修改/etc/PG.conf文件因为是单网口，所以数据口和管理口都需要配置成eth0，后面不要加任何东西 1DATA_PORTS 修改成：DATA_PORTS=&quot;eth0&quot; 修改端口上传文件，修改配置需要上传一个joskmc文件（文件在文末）在/etc/PG.conf中新增一下一行 1HTTPS_PORT=2194 执行joskmc1/root/joskmc tcp 2194 修改：/etc/rc.local，增加一下三行12sleep 10/root/joskmc tcp 2194 2、进行隧道配置（海外）(1)、登录WEB页面，修改网卡方向默认账号密码：admin/panabit系统概况 → 网络接口：eth0，修改成对外，只有对外才可以创建WAN线路 (2)、创建WAN线路应用路由 → 接口线路：需要注意，Mac地址必须克隆 (3)、创建IWAN连接账号对象管理 → 账号管理 → 组织架构：地址范围：这一块可以自己定一个内网的IP段就可以，不要冲突就好地址范围需要把网关地址留出来！！！！！对象管理 → 账号管理 → 本地账号：处理用户组需要选择前面创建的用户组，其他的根据实际情况填写 (4)、创建iWAN服务应用路由 → iWAN服务 → 服务列表：注意：服务器网关地址要和你前面设置的地址范围要在一块，并且需要排除这个地址的下发应用路由 → iWAN服务 → 服务映射：根据配置情况选择即可iWAN使用的是UDP连接，因此端口需要开放UDP (5)、创建策略路由应用路由 → 策略路由：需要添加一条回程的全程路由，要不然DNS牵引、FQ都会失败这里选择iWAN的线路 3、客户端配置（办公网）(1)、新建WAN线路应用路由 → 接口线路 → WAN线路：按照信息提示填写即可完成iWAN线路配置注意：必须有一个外网的网卡，并且最好把加密开起来 (2)、设置DNS牵引应用路由 → DNS管控：海外域名是一个域名群组，可以自己修改主要解决DNS污染问题，要不然可能部分网站会无法访问这里有一个很注意的点，就是你的DNS，访问DNS的链路必须经过PA，否则牵引不会生效 (3)、设置策略路由应用路由 → 策略路由：我这边直接拿了飞连的609海外分流IP段进行分流，你也可以自己修改（文末下载）主要为了只有需要海外的才出去，不能把所有的流量全部导出去 附件169IP段： https://www.123pan.com/s/cRk7Vv-frSsH 提取码:NzAFLinux操作系统： https://www.123pan.com/s/cRk7Vv-arSsH 提取码:A5MCjoskmc： https://www.123pan.com/s/cRk7Vv-BrSsH 提取码:kTu9","link":"/2023/02/17/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%8A%9E%E5%85%AC%E7%BD%91Panabit%E5%85%A8%E7%90%83%E5%8C%96%E7%9A%84%E6%94%B9%E9%80%A0%E8%AE%A1%E5%88%92/"},{"title":"安装&amp;破解Openvpn Access Server","text":"在线安装（需要翻墙）12yum -y install https://as-repository.openvpn.net/as-repo-centos7.rpmyum -y install openvpn-as 管理员登录首先需要修改管理员密码 1passwd openvpn 输入之后可以登录管理员页面了。 如果密码一直错误的话，说明修改失败了，可以查看下原来的密码是什么 1cat /usr/local/openvpn_as/init.log 登录后点击User Management–&gt;User Permissions 添加用户 破解用户数 主要操作的文件是一个名叫 pyovpn-2.0-pyx.x.egg 的文件，以我了解的情况来看，从 2.5.0 到 2.9.x 文件名一直都是这个，只是不同版本里面的内容不一样. 这个文件有点类似 Java 当中的 jar 库文件，也是一个 zip 压缩文件，里面包含了一些 Python 的字节码文件. 破解的原理大概是在 Python 中采用类似 Java 动态代理的技术，将原本读取用户属性的调用返回值拦截，修改用户限制数量再返回. 方法2.9.0 以下版本破解的目标文件是 /pyovpn/lic/uprop.pyo, 2.9.0 及以上是 /pyovpn/lic/uprop.pyc; 按照网上流行的破解方法，把这个文件解压出来并改名为 uprop2.pyo 或 uprop2.pyc, 然后新建一个 uprop.py 文件，内容如下: **2.9.0**以下版本内容: 12345678910111213141516import uprop2old_figure = Nonedef new_figure(self, licdict): ret = old_figure(self, licdict) ret['concurrent_connections'] = 1024 return retfor x in dir(uprop2): if x[:2] == '__': continue if x == 'UsageProperties': exec('old_figure = uprop2.UsageProperties.figure') exec('uprop2.UsageProperties.figure = new_figure') exec('%s = uprop2.%s' % (x, x)) **2.9.0**及以上版本内容: 12345678910111213141516from pyovpn.lic import uprop2old_figure = Nonedef new_figure(self, licdict): ret = old_figure(self, licdict) ret['concurrent_connections'] = 1024 return retfor x in dir(uprop2): if x[:2] == '__': continue if x == 'UsageProperties': exec('old_figure = uprop2.UsageProperties.figure') exec('uprop2.UsageProperties.figure = new_figure') exec('%s = uprop2.%s' % (x, x)) 再将上面的 uprop.py 编译为库文件 uprop.pyo 或 uprop.pyc: 1234# &lt;2.9.0python2 -O -m compileall uprop.py# &gt;=2.9.0python3 -O -m compileall uprop.py &amp;&amp; mv __pycache__/uprop.cpython-37.opt-1.pyc uprop.pyc 注意 uprop.cpython-37.opt-1.pyc 文件名会随着 python 版本变化而变化. 现在我们得到了一个改文件名的文件 uprop2.pyo 或 uprop2.pyc, 和一个编译出来的 uprop.pyo 或 uprop.pyc; 把这两个文件压缩到 pyovpn-2.0-pyx.x.egg 的 /pyovpn/lic/ 目录下，然后去服务器替换目标文件，重启服务就 OK 了. 所有的操作命令12345678910111213141516# 把操作的文件复制出来到另外的一个文件夹下面操作cd /usr/local/openvpn_as/lib/python &amp; mkdir pojie &amp; cp python/pyovpn-2.0-py3.6.egg ./pojie &amp; cd pojie/# 改一个文件名，防止后面打包的时候把源文件覆盖了mv pyovpn-2.0-py3.6.egg pyovpn-2.0-py3.6.egg.bak &amp; unzip pyovpn-2.0-py3.6.egg.bak# 进入到需要修改的目录cd pyovpn/lic# 复制源文件改名mv uprop.pyc uprop2.pyc# 新增一个py文件，然后把文件内容复制进去，并保存vi uprop.py# 退到 pojie 文件夹，进行打包zip -r pyovpn-2.0-py3.6.egg EGG-INFO/ common/ pyovpn/# 复制文件到运行目录，覆盖cp pyovpn-2.0-py3.6.egg /usr/local/openvpn_as/lib/python# 重启服务systemctl restart openvpnas","link":"/2022/12/13/openvpn/openvpn-access-server/"},{"title":"openvpn-auth（支持企业微信认证&amp;LDAP）","text":"方案介绍时序图 其中有两个地方需要修改 corpid: 企业微信的企业ID corpsecret: 拥有通讯录的企业微信的Secret 代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package authimport ( &quot;io/ioutil&quot; &quot;log&quot; &quot;net/http&quot; &quot;strconv&quot; &quot;github.com/tidwall/gjson&quot;)func GetAccessToken() string { return GetWecomToken()}// 从企业微信获取Tokenfunc GetWecomToken() string { //创建一个请求 req, err := http.NewRequest(&quot;GET&quot;, &quot;https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=corpid&amp;corpsecret=corpsecret&quot;, nil) if err != nil { log.Println(&quot;NewRquest:&quot;, err) } client := &amp;http.Client{} //设置请求头 req.Header.Set(&quot;Content-Type&quot;, &quot;application/json; charset=utf-8&quot;) //发送请求 resp, err := client.Do(req) //关闭请求 defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) access_token := gjson.Get(string(body), &quot;access_token&quot;) return access_token.Str}// 获取员工信息func WeComAuth(userId string) bool { //创建一个请求 req, err := http.NewRequest(&quot;GET&quot;, `https://qyapi.weixin.qq.com/cgi-bin/user/get?access_token=`+GetAccessToken()+`&amp;userid=`+userId, nil) if err != nil { log.Println(&quot;NewRquest:&quot;, err) } client := &amp;http.Client{} //设置请求头 req.Header.Set(&quot;Content-Type&quot;, &quot;application/json; charset=utf-8&quot;) //发送请求 resp, err := client.Do(req) //关闭请求 defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) errcode := gjson.Get(string(body), &quot;errcode&quot;) int, err := strconv.Atoi(errcode.Str) return int == 0} 使用方式修改/etc/openvpn/server.conf的验证方式，可以吧其他的验证去掉 1auth-user-pass-verify /etc/openvpn/openvpn-wecom-password via-file 加解密方式因为用到了客户端传过来的时候的加密方式，因此两边的加密方式必须一致 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package utilimport ( &quot;bytes&quot; basicAES &quot;crypto/aes&quot; &quot;crypto/cipher&quot; &quot;encoding/base64&quot;)type Aes struct { securityKey []byte iv []byte}/** * constructor */func AesTool() *Aes { return &amp;Aes{[]byte(&quot;123&quot;), []byte(&quot;123&quot;)}}/** * 加密 * @param string $plainText 明文 * @return bool|string */func (a Aes) Encrypt(plainText string) (string, error) { block, err := basicAES.NewCipher(a.securityKey) if err != nil { return &quot;&quot;, err } plainTextByte := []byte(plainText) blockSize := block.BlockSize() plainTextByte = AddPKCS7Padding(plainTextByte, blockSize) cipherText := make([]byte, len(plainTextByte)) mode := cipher.NewCBCEncrypter(block, a.iv) mode.CryptBlocks(cipherText, plainTextByte) return base64.StdEncoding.EncodeToString(cipherText), nil}/** * 解密 * @param string $cipherText 密文 * @return bool|string */func (a Aes) Decrypt(cipherText string) (string, error) { block, err := basicAES.NewCipher(a.securityKey) if err != nil { return &quot;&quot;, err } cipherDecodeText, decodeErr := base64.StdEncoding.DecodeString(cipherText) if decodeErr != nil { return &quot;&quot;, decodeErr } mode := cipher.NewCBCDecrypter(block, a.iv) originCipherText := make([]byte, len(cipherDecodeText)) mode.CryptBlocks(originCipherText, cipherDecodeText) originCipherText = StripPKSC7Padding(originCipherText) return string(originCipherText), nil}/** * 填充算法 * @param string $source * @return string */func AddPKCS7Padding(ciphertext []byte, blockSize int) []byte { padding := blockSize - len(ciphertext)%blockSize paddingText := bytes.Repeat([]byte{byte(padding)}, padding) return append(ciphertext, paddingText...)}/** * 移去填充算法 * @param string $source * @return string */func StripPKSC7Padding(cipherText []byte) []byte { length := len(cipherText) unpadding := int(cipherText[length-1]) return cipherText[:(length - unpadding)]}","link":"/2022/12/13/openvpn/openvpn-auth/"},{"title":"openvpn动态下发权限","text":"首先了解我们为什么要动态下发 开源的openvpn并不支持权限管理，大部分在做权限管理的时候使用的都是根据来源IP或IP段通过iptables/交换机来进行权限控制 权限控制太广了，根本无法很好的去做管理后台的配置，特别是需要用户组来进行区分的时候，那就更困难了 权限下发的逻辑 用到的技术 ipset iptables 主要脚本内容连接脚本1234567891011121314/sbin/ipset create ${common_name}-${common_ip} hash:ip/sbin/ipset create ${common_name}-${common_ip}-drop hash:ip# 这里是动态去你的后端获取出来的允许访问的列表，接口自己去实现for index in `seq 0 $permissionsAcceptLength`; do /sbin/ipset add ${common_name}-${common_ip} ${permissionsAccept[$index]//\\&quot;/}donefor index in `seq 0 $permissionsDropLength`; do /sbin/ipset add ${common_name}-${common_ip}-drop ${permissionsDrop[$index]//\\&quot;/}done# 设置iptables/sbin/iptables -A FORWARD -s $common_ip -m set --match-set ${common_name}-${common_ip} dst -j ACCEPT/sbin/iptables -A FORWARD -s $common_ip -m set --match-set ${common_name}-${common_ip}-drop dst -j DROP/sbin/iptables -A FORWARD -s $common_ip -j DROP 断开脚本12345/sbin/iptables -D FORWARD -s $ifconfig_pool_remote_ip -m set --match-set ${common_name}-${ifconfig_pool_remote_ip} dst -j ACCEPT/sbin/iptables -D FORWARD -s $ifconfig_pool_remote_ip -m set --match-set ${common_name}-${ifconfig_pool_remote_ip}-drop dst -j DROP/sbin/iptables -D FORWARD -s $ifconfig_pool_remote_ip -j DROP/sbin/ipset destroy ${common_name}-${ifconfig_pool_remote_ip}/sbin/ipset destroy ${common_name}-${ifconfig_pool_remote_ip}-drop 如果在运行的过程中出现脚本权限不足123chmod 766 connect.sh disconnect.shchmod a+x connect.sh disconnect.shchmod +s connect.sh disconnect.sh","link":"/2022/12/14/openvpn/openvpn-dynamic-route-permissions/"},{"title":"清理自定义DHCP下发，异常断开导致IP地址占用的问题","text":"背景因为OpenVpn存在断开重连的机制，如果突然出现网络抖动，用户端没有触发断开命令，但是同时又触发了重新连接的命令，这时候VPN这里就会重新给下发一个新的地址，但是老的地址不会回收掉，这个也是很早之前DHCP被用完的真正原因 处理方式在每一台openvpn的机器上新增一个shell脚本做定时任务，每天临晨2点开始循环遍历 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/bin/bashIFS=$'\\n' # 修改默认分隔符OLDIFS=&quot;$IFS&quot; # 清理无效的IP地址function clearIp(){ # 取出当前已经分配下去的所有IP地址 result=$(curl -s &quot;后端获取当前使用IP的接口地址&quot;); ipList=`echo $result | jq '.d.result'`; ipListLength=`echo $ipList | jq '.|length'`; date=`date &quot;+%Y-%m-%d %H:%M:%S&quot;` # 循环所有的数据 for index in `seq 0 $ipListLength` do ip=`echo $ipList | jq -r &quot;.[$index].ip&quot;`; common_name=`echo $ipList | jq -r &quot;.[$index].user&quot;` # 拿到当前真正在使用的IP地址 useIp=`cat /var/log/openvpn/status.log | grep CLIENT_LIST | awk '{if (NR&gt;1){print $1}}' | cut -d ',' -f 4` # 如果当前IP已经不在使用了，那么就需要释放，防止后期地址池不够用的情况 if [[ &quot;${useIp[@]}&quot; =~ &quot;${ip}&quot; ]]; then echo &quot;${date} | ${ip} | 当前IP属于使用状态，无需释放&quot;; else curl -s &quot;释放IP的接口地址&quot; &gt;&gt; /var/log/openvpn/disconnect.log echo &quot;${date} | ${ip} | ${common_name} | 当前IP需要释放&quot; fi done} # 清理Iptable的规则function clearIptable(){ iptableResult=($(iptables -L | grep 10.207 | grep ACCEPT | awk '{print $7}')) iptableResultCount=($(iptables -L | grep 10.207 | grep ACCEPT | awk '{print $7}' | wc -l)) date=`date &quot;+%Y-%m-%d %H:%M:%S&quot;` for item in ${iptableResult[@]} do ip=`echo $item | cut -d '-' -f 2` common_name=`echo $item | cut -d '-' -f 1` ifconfig_pool_remote_ip=$ip useIp=`cat /var/log/openvpn/status.log | grep CLIENT_LIST | awk '{if (NR&gt;1){print $1}}' | cut -d ',' -f 4` # 如果当前IP已经不在使用了，那么就需要释放，防止后期地址池不够用的情况 if [[ &quot;${useIp[@]}&quot; =~ &quot;${ip}&quot; ]]; then echo &quot;${date} | ${ip} | 当前IP属于使用状态，无需释放&quot;; else echo &quot;${date} | ${ifconfig_pool_remote_ip} | ${common_name} | 当前IP需要释放&quot; /sbin/iptables -D FORWARD -s $ifconfig_pool_remote_ip -m set --match-set ${common_name}-${ifconfig_pool_remote_ip} dst -j ACCEPT /sbin/iptables -D FORWARD -s $ifconfig_pool_remote_ip -m set --match-set ${common_name}-${ifconfig_pool_remote_ip}-drop dst -j DROP /sbin/iptables -D FORWARD -s $ifconfig_pool_remote_ip -j DROP /sbin/ipset destroy ${common_name}-${ifconfig_pool_remote_ip} /sbin/ipset destroy ${common_name}-${ifconfig_pool_remote_ip}-drop fi done} clearIp()clearIptable()","link":"/2023/02/16/openvpn/clearOpenvpnInvalidIp/"},{"title":"zabbix 警报推送至企业微信（图文版）","text":"新增Python脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131# encoding: utf-8import sysimport requestsimport jsonimport osimport timeimport re url = 'http://10.1.1.59/zabbix/api_jsonrpc.php'headers = {'Content-Type': 'application/json-rpc'}graph_path = '/data/zabbix/images/' # 定义图片存储路径graph_url = 'http://10.1.1.59/zabbix/chart.php' # 定义图表的urlloginurl = &quot;http://10.1.1.59/zabbix/index.php&quot; # 定义登录的url def uploadImg(path,accessToken): #img_url = &quot;https://qyapi.weixin.qq.com/cgi-bin/webhook/upload_media?key=&quot; + key + &quot;&amp;type=file&quot; img_url = &quot;https://qyapi.weixin.qq.com/cgi-bin/media/uploadimg?access_token=&quot;+accessToken files = {'media': open(path, 'rb')} r = requests.post(img_url, files=files) re = json.loads(r.text) print(re) return re['url'] def get_itemid(message): #print(message) itemid = re.search(r'ITEMID:(\\d+)', message).group(1) #itemid = 1 return itemid def get_imgUrl(itemid): session = requests.Session() try: loginheaders = { &quot;Host&quot;: &quot;10.1.1.59&quot;, &quot;Accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9&quot; } # 定义请求消息头 payload = { &quot;name&quot;: 'yantao', &quot;password&quot;: 'xxxxxxx', &quot;autologin&quot;: &quot;1&quot;, &quot;enter&quot;: &quot;Sign in&quot;, } # 定义传入的data login = session.post(url=loginurl, headers=loginheaders, data=payload) print(login) graph_params = { &quot;from&quot;: &quot;now-10m&quot;, &quot;to&quot;: &quot;now&quot;, &quot;itemids&quot;: itemid, &quot;width&quot;: &quot;400&quot;, } # 定义获取图片的参数 graph_req = session.get(url=graph_url, params=graph_params) # 发送get请求获取图片数据 time_tag = time.strftime(&quot;%Y%m%d%H%M%S&quot;, time.localtime()) graph_name = 'baojing_' + time_tag + '.png' # 用报警时间来作为图片名进行保存 graph_name = os.path.join(graph_path, graph_name) # 使用绝对路径保存图片 with open(graph_name, 'wb', ) as f: f.write(graph_req.content) # 将获取到的图片数据写入到文件中去 return graph_name except Exception as e: print(e) return False def getAccessToken(): api_url = &quot;https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=corpid&amp;corpsecret=corpsecret&quot; content = requests.get(api_url) #print(content.json()) return content.json().get(&quot;access_token&quot;) def getImgUrl(mediaId,accessToken): api_url = &quot;https://qyapi.weixin.qq.com/cgi-bin/media/get?access_token=&quot;+accessToken+&quot;&amp;media_id=&quot;+mediaId content = requests.get(api_url) print(mediaId) print(content.json()) return content.json().get(&quot;url&quot;) def send_message(imgUrl,title,desc,openUrl,key): # 发送消息 url = &quot;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=&quot; + key # message = title # sys.argv[3] params = { &quot;msgtype&quot;: &quot;template_card&quot;, &quot;template_card&quot;: { &quot;card_type&quot;: &quot;news_notice&quot;, &quot;source&quot;: { &quot;desc&quot;: &quot;Zabbix网络警报&quot;, &quot;desc_color&quot;: 0 }, &quot;main_title&quot;:{ &quot;title&quot;:&quot;Zabbix网络警报&quot;, }, &quot;quote_area&quot;:{ &quot;type&quot;:0, &quot;quote_text&quot;:desc }, &quot;card_image&quot;: { &quot;url&quot;: imgUrl }, &quot;card_action&quot;: { &quot;type&quot;: 1, &quot;url&quot;: openUrl, &quot;appid&quot;: &quot;APPID&quot;, &quot;pagepath&quot;: &quot;PAGEPATH&quot; } } } req = requests.post(url, data=json.dumps(params)) print(req.json()) if __name__ == '__main__': message = sys.argv[1] print(message) itemid = get_itemid(message) imgpath = get_imgUrl(itemid) accessToken = getAccessToken(); imgUrl = uploadImg(imgpath,accessToken) #print(itemid) #print(imgpath) print(imgUrl) send_message(imgUrl,sys.argv[2],sys.argv[3],imgUrl,sys.argv[4]) #accessToken = getAccessToken() 新增SH脚本123#!/bin/bashecho $1 &gt;&gt; /data/zabbix/log.logpython /usr/lib/zabbix/alertscripts/wxcom.py $1 $2 $3 $4 把两个文件都放到这个目录下：/usr/lib/zabbix/alertscripts/ 配置媒介","link":"/2022/12/13/zabbix/zabbix-wecom/"}],"tags":[{"name":"openwrt","slug":"openwrt","link":"/tags/openwrt/"},{"name":"多拨","slug":"多拨","link":"/tags/%E5%A4%9A%E6%8B%A8/"},{"name":"Obsidian","slug":"Obsidian","link":"/tags/Obsidian/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"chatgpt","slug":"chatgpt","link":"/tags/chatgpt/"},{"name":"gpt","slug":"gpt","link":"/tags/gpt/"},{"name":"telegram","slug":"telegram","link":"/tags/telegram/"},{"name":"zabbix","slug":"zabbix","link":"/tags/zabbix/"},{"name":"tcp","slug":"tcp","link":"/tags/tcp/"},{"name":"udp","slug":"udp","link":"/tags/udp/"},{"name":"curl","slug":"curl","link":"/tags/curl/"},{"name":"代理","slug":"代理","link":"/tags/%E4%BB%A3%E7%90%86/"},{"name":"检测","slug":"检测","link":"/tags/%E6%A3%80%E6%B5%8B/"},{"name":"透明代理","slug":"透明代理","link":"/tags/%E9%80%8F%E6%98%8E%E4%BB%A3%E7%90%86/"},{"name":"vpn","slug":"vpn","link":"/tags/vpn/"},{"name":"流量转发","slug":"流量转发","link":"/tags/%E6%B5%81%E9%87%8F%E8%BD%AC%E5%8F%91/"},{"name":"办公网","slug":"办公网","link":"/tags/%E5%8A%9E%E5%85%AC%E7%BD%91/"},{"name":"全球化","slug":"全球化","link":"/tags/%E5%85%A8%E7%90%83%E5%8C%96/"},{"name":"全球办公","slug":"全球办公","link":"/tags/%E5%85%A8%E7%90%83%E5%8A%9E%E5%85%AC/"},{"name":"国际化","slug":"国际化","link":"/tags/%E5%9B%BD%E9%99%85%E5%8C%96/"},{"name":"Panabit","slug":"Panabit","link":"/tags/Panabit/"},{"name":"iwan","slug":"iwan","link":"/tags/iwan/"},{"name":"sd-wan","slug":"sd-wan","link":"/tags/sd-wan/"},{"name":"2.9.0","slug":"2-9-0","link":"/tags/2-9-0/"},{"name":"openvpn","slug":"openvpn","link":"/tags/openvpn/"},{"name":"openvpn access server","slug":"openvpn-access-server","link":"/tags/openvpn-access-server/"},{"name":"破解","slug":"破解","link":"/tags/%E7%A0%B4%E8%A7%A3/"},{"name":"openvpn-auth","slug":"openvpn-auth","link":"/tags/openvpn-auth/"},{"name":"wecom","slug":"wecom","link":"/tags/wecom/"},{"name":"企业微信","slug":"企业微信","link":"/tags/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1/"},{"name":"认证","slug":"认证","link":"/tags/%E8%AE%A4%E8%AF%81/"},{"name":"ldap","slug":"ldap","link":"/tags/ldap/"},{"name":"权限","slug":"权限","link":"/tags/%E6%9D%83%E9%99%90/"},{"name":"动态下发","slug":"动态下发","link":"/tags/%E5%8A%A8%E6%80%81%E4%B8%8B%E5%8F%91/"},{"name":"dhcp","slug":"dhcp","link":"/tags/dhcp/"},{"name":"报警","slug":"报警","link":"/tags/%E6%8A%A5%E8%AD%A6/"}],"categories":[],"pages":[]}